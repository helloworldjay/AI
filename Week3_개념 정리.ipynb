{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP637PL4MQfPuTUF/U4CDpe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/helloworldjay/AI_Precourse/blob/master/Week3_%EA%B0%9C%EB%85%90%20%EC%A0%95%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJxftSj1Twsr",
        "colab_type": "text"
      },
      "source": [
        "# 머신러닝을 위한 기초 수학"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZmsk9unSid0",
        "colab_type": "text"
      },
      "source": [
        "## JSON(Javascript Object Notation)\n",
        "데이터를 효율적으로 저장하고 교환하는데 사용(텍스트 데이터 형식중 하나) \n",
        "\n",
        "- 사람이 읽고 쓰기에 쉽다.\n",
        "- 컴퓨터가 파싱하고 생성하기 쉽다.\n",
        "\n",
        "파이썬에서 JSON으로 변환되며 list, tuple -> array\n",
        "JSON에서 파이썬으로 변환되며 array -> list, tuple로 변환된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTbuoz9CSVr3",
        "colab_type": "text"
      },
      "source": [
        "## 분류 문제\n",
        "\n",
        "퍼셉트론(Perceptron)\n",
        "\n",
        "- 여러개의 입력을 받아 각각의 값에 가중치를 곱해 모두 더하는 함수\n",
        "\n",
        "- 선형 분리 불가능 문제(하나의 선으로 구분하지 못하는 문제)의 데이터셋에는 수렴하지 못한다는 단점이 있다.\n",
        "\n",
        "로지스틱 회귀\n",
        "\n",
        "- 분류를 확률로 생각하는 방식\n",
        "\n",
        "- 수치가 아닌 어느 클래스에 분류 되는지 구하는 것\n",
        "\n",
        "- 로지스틱 시그모이드 함수\n",
        "  f(x) = 1/(1+e^(-z))\n",
        "  when z = w^T * x(w:가중치 벡터, x:입력 데이터 변수, T: 전치 행렬)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjPbPmQ0Wzeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def sigmoid(z):\n",
        "  return 1.0/(1.0 + np.exp(-z))\n",
        "# 시각화 코드\n",
        "z = np.arange(-7,7,0.1) # 범위를 -7에서 7까지, 간격은 촘촘하게\n",
        "f_x = sigmoid(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsCW5-aVZKXn",
        "colab_type": "text"
      },
      "source": [
        "미지의 데이터 x가 주어질 때, 가로로 긴 사각형일 경우 1, 세로로 긴 사각형일 경우 0\n",
        "\n",
        "P(y=1|x) = f(x) -> 미지의 데이터 x가 주어졌을 때 그 데이터가 가로로 길 확률 f(x)\n",
        "\n",
        "만약 f(x)가 0.7이라면, 이 사각형이 가로로 길 확률은 70%이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1VEFEq2aSsT",
        "colab_type": "text"
      },
      "source": [
        "서포트 벡터 머신(SVM)\n",
        ": 마진을 최대화\n",
        "\n",
        "레이블을 구분하기 위한 초평면(결정경계)를 그리고 그 다음 초평면은 마진이라는 것을 구하는데, 마진은 초평면과 가장 가까운 훈련데이터와의 거리이고, 이러한 데이터들을 서포트 벡터라고 한다.\n",
        "\n",
        "선형 분리 불가능 문제에서도 강력한 힘을 발휘한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11Jw5AaPT8OJ",
        "colab_type": "text"
      },
      "source": [
        "# 머신러닝 - 분류문제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oApXg5s6Syqi",
        "colab_type": "text"
      },
      "source": [
        "## 머신러닝 알고리즘 훈련을 위한 단계\n",
        "\n",
        "1. 변수를 선택하고 훈련데이터를 수집\n",
        "2. 모델의 성능 지표를 선택\n",
        "3. 분류 모델과 최적화 알고리즘을 선택\n",
        "4. 모델의 성능 평가\n",
        "5. 모델 튜닝"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAldcjOkc99q",
        "colab_type": "text"
      },
      "source": [
        "목적 함수의 목적 -> 정보 이득(IG) 최대화\n",
        "\n",
        "1. 지니 불순도\n",
        "2. 엔트로피\n",
        "3. 분류오차"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moUl7Rxlki95",
        "colab_type": "text"
      },
      "source": [
        "0. 결정 학습트리에서 노드를 ____이 최대가 되는 특성으로 데이터를 나누게 된다.\n",
        "정보이득\n",
        "\n",
        "1. 결정 트리 학습(Decision tree)에서 너무 많은 분기로 인해 과적합 되는 걸 막기 위해 분기를 재조정하는 방법을 무엇이라 하는가? \n",
        "트리 가지치기(Pruning)\n",
        "\n",
        "2. KNN 알고리즘에 대한 사실로 올바르지 않은 것은?\n",
        " \n",
        "최적의 K를 선택하기 어렵다.\n",
        " \n",
        "고차원의 데이터나 데이터 수가 많아질수록 계산 비용이 높아진다.\n",
        " \n",
        "충분한 알고리즘 학습 후 사용 가능하다.\n",
        " \n",
        "학습 유형은 지도학습에 해당한다.\n",
        "\n",
        "3. 고정된 크기의 훈련 데이터셋 차원이 늘어남에 따라 특성 공간이 점점 희소해 지는 현상을 무엇이라 하는가? \n",
        "차원의 저주"
      ]
    }
  ]
}